[Service]
# ─── Storage: TUDO no RAID (5.4TB livres, 2.9 GB/s) ─────────
# Modelos salvos no RAID
Environment="OLLAMA_MODELS=/mnt/winraid/__KALI_SAFE/models"
# Downloads intermediários e tmp no RAID (modelos de 20GB+ não entupem sistema)
Environment="OLLAMA_TMPDIR=/mnt/winraid/__KALI_SAFE/tmp/ollama"
# HOME do daemon no RAID (logs, history)
Environment="HOME=/mnt/winraid/__KALI_SAFE/logs/ollama"

# ─── Performance: RTX 4090 otimizada ─────────────────────────
# Flash Attention: 2x mais rápido, menos VRAM no KV cache
Environment="OLLAMA_FLASH_ATTENTION=1"
# KV cache quantizado: economiza ~40% de VRAM no context window
Environment="OLLAMA_KV_CACHE_TYPE=q8_0"
# Modelo NUNCA descarrega — é o único, sem competição por VRAM
Environment="OLLAMA_KEEP_ALIVE=-1"
# Requests paralelos (até 2 queries simultâneas)
Environment="OLLAMA_NUM_PARALLEL=2"
# CUDA shader cache persistente no RAID
Environment="CUDA_CACHE_PATH=/mnt/winraid/__KALI_SAFE/caches/cuda"
# Host: bind em todas interfaces (útil para acesso remoto futuro)
Environment="OLLAMA_HOST=0.0.0.0:11434"

# ─── GPU Persistence Mode ────────────────────────────────────
# Mantém driver CUDA inicializado, elimina latência de cold start
ExecStartPost=/usr/bin/nvidia-smi -pm 1
